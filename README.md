# Проектный практикум 3. Учебная задача

---
**Команда №1**
- Осипов Н.В.
- Сокирка А.В.
- Султанов Э.М.
- Шибакова А.А.
---

## Генерация отзывов с использованием нейронной сети

### Описание проекта

Целью проекта является создание нейронной сети, способной генерировать текстовые отзывы о различных местах на основе входных параметров, таких как категория места, средний рейтинг и ключевые слова. Для этого был проведен анализ и подготовка данных, а также расширение датасета новыми признаками.

Данные для проекта взяты из открытого датасета отзывов на организации в России, доступного на [GitHub](https://github.com/yandex/geo-reviews-dataset-2023). Датасет содержит 500 000 уникальных отзывов, опубликованных на Яндекс Картах с января по июль 2023 года.

Данные: https://github.com/yandex/geo-reviews-dataset-2023


### Состав датасета

Датасет содержит следующие столбцы:
- **address**: Адрес организации.
- **name_ru**: Название организации.
- **rubrics**: Список рубрик, к которым относится организация.
- **rating**: Оценка пользователя (от 0 до 5).
- **text**: Текст отзыва.

---

### Шаги выполнения работы

#### 1. Импорт библиотек
Для выполнения анализа и обработки данных были использованы следующие библиотеки:
- `pandas` для работы с данными.
- `matplotlib` и `seaborn` для визуализации.
- `nltk` и `pymorphy2` для обработки текста.
- `sklearn` для кластеризации и анализа TF-IDF.
- `geopy` для геокодирования адресов.

#### 2. Загрузка и первичная обработка данных
- Датасет был загружен в формате `.parquet`.
- Проведена очистка данных:
  - Удалены строки с пропущенными значениями.
  - Удалены дубликаты текстов отзывов.
- Вычислена базовая статистика:
  - Количество уникальных организаций, адресов и рубрик.  
  - Построены графики распределения уникальных объектов (организаций, адресов, рубрик).
  ![img](https://github.com/sultanovemil/PP_3_URFU/blob/main/img/destribution.png)
	

#### 3. Геокодирование адресов
- Попытка извлечь координаты (широта и долгота) с использованием библиотеки `geopy` и сервиса Nominatim.
- Из-за ограничений API и длительного времени загрузки данных через Docker, геокодирование было отложено.

#### 4. Расширение данных
##### 4.1. Лемматизация текста
- Для обработки текстов отзывов была реализована функция лемматизации с использованием библиотеки `pymorphy2`.
- Удалены стоп-слова, добавлены дополнительные стоп-слова для русского языка.

##### 4.2. Выделение ключевых слов
- С помощью TF-IDF анализа были выделены ключевые слова для каждой рубрики.
- Датасет был дополнен новым признаком `kw_by_rub` — ключевые слова, соответствующие рубрикам организации.

![img](https://github.com/sultanovemil/PP_3_URFU/blob/main/img/key_words.png)

##### 4.3. Замена рейтинга
- Из-за дисбаланса в распределении рейтингов (преобладание оценок "5") рейтинг был заменен на средний рейтинг организации.
- Построен график распределения отзывов по рейтингу.
![img](https://github.com/sultanovemil/PP_3_URFU/blob/main/img/Rating_destribution.png)

#### 5. Очистка текстов отзывов
- Проведена базовая очистка текстов:
  - Приведение текста к нижнему регистру.
  - Удаление HTML-тегов, лишних символов, цифр и лишних пробелов.
  - Замена нескольких точек на одну.

---

### Итоговый датасет

После обработки и расширения данных датасет содержит следующие столбцы:
- **address**: Адрес организации.
- **name_ru**: Название организации.
- **rubrics**: Список рубрик.
- **rating**: Средний рейтинг организации.
- **text**: Очищенный текст отзыва.
- **aspects**: Лемматизированный текст отзыва с выделением существительных.
- **kw_by_rub**: Ключевые слова, соответствующие рубрикам организации.

---

### Результаты

1. Датасет был очищен от пропусков и дубликатов.
2. Добавлены новые признаки:
   - Лемматизированный текст отзывов.
   - Ключевые слова для каждой рубрики.
   - Средний рейтинг организации.
3. Проведена базовая визуализация данных.
4. Данные подготовлены для обучения нейронной сети.

---

### Вторая часть проекта: Обучение нейронной сети

Во второй части проекта была реализована дообученная нейронная сеть на основе модели GPT-2 `sberbank-ai/rugpt3small_based_on_gpt2`, способная генерировать текстовые отзывы о различных местах. Для обучения использовались данные, подготовленные на первом этапе проекта, включающие очищенные тексты отзывов, категории мест, средние рейтинги и ключевые слова.


### Шаги выполнения работы

#### 1. Импорт библиотек
Для выполнения задачи использовались следующие библиотеки:
- `pandas` для работы с данными.
- `transformers` для работы с предобученными моделями и токенизаторами.
- `datasets` для преобразования данных в формат, совместимый с библиотекой `transformers`.

#### 2. Загрузка и подготовка данных
- Данные были подготовленного на первом этапе проекта.
- Проведена проверка на наличие пустых значений в столбце `text`. Строки с пустыми значениями были удалены.
- Для обучения модели текст отзывов был преобразован в формат, включающий:
  - Категорию места.
  - Средний рейтинг.
  - Ключевые слова.
  - Текст отзыва.

- Данные были преобразованы в формат `Dataset` из библиотеки `datasets` для дальнейшей токенизации.

#### 3. Токенизация данных
- Для токенизации использовалась предобученная модель `sberbank-ai/rugpt3small_based_on_gpt2`.
- Тексты были токенизированы с учетом следующих параметров:
  - Максимальная длина текста: 512 токенов.
  - Заполнение до максимальной длины.
  - Добавление меток (`labels`), совпадающих с токенизированным входом (`input_ids`), для обучения модели.

#### 4. Загрузка предобученной модели
Для дообучения использовалась предобученная модель sberbank-ai/rugpt3small_based_on_gpt2. Дообучение проводилось на мощностях Google Colab с использованием GPU Tesla A100, что позволило значительно ускорить процесс обучения и сократить время выполнения задач.


#### 5. Настройка параметров обучения
- Для обучения модели были заданы следующие параметры:
  - Количество эпох: 3.
  - Размер батча: 32.
  - Шаги накопления градиента: 8.
  - Использование смешанной точности (`fp16`) для ускорения обучения.
  - Сохранение модели каждые 500 шагов.
  - Логирование каждые 100 шагов.
  - Ограничение на количество сохраняемых чекпоинтов: 2.

#### 6. Обучение модели
- Обучение модели проводилось с использованием класса `Trainer` из библиотеки `transformers`.

![img](https://github.com/sultanovemil/PP_3_URFU/blob/main/img/learning.PNG)

---

### Оценка качества модели по генерации отзывов

В данном разделе мы представляем шаги по оценке качества модели, предварительно обученной на основе нейронной сети. Для анализа были сгенерированы отзывы по пяти самым популярным категориям из датасета. Оценка качества проводилась с использованием датасета, полученного путем извлечения ключевых слов по категориям, на которых обучалась модель.

#### Процесс генерации отзывов

Для каждой из пяти категорий было сгенерировано по пять отзывов с рейтингами от 1 до 5. В процессе генерации для каждого отзыва также вычислялось значение метрики perplexity. Перплексия — это мера языковой связности и предсказуемости текста, которая позволяет оценить, насколько хорошо модель справляется с задачей генерации текста. Низкие значения perplexity указывают на более высокую языковую грамотность и связность сгенерированного текста.

---
При генерации были использованы следующие параметры:
- max_length=150,
- num_return_sequences=1,
- no_repeat_ngram_size=2,
- do_sample=True,
- top_p=0.95,
- top_k=60,
- temperature=1
---

Все сгенерированные данные были добавлены в новый DataFrame с следующими столбцами:
- **text**: текст отзыва
- **category**: категория отзыва
- **rating**: рейтинг отзыва
- **key_words**: ключевые слова, связанные с категорией
- **perplexity**: значение perplexity для текста отзыва

#### Визуальная и количественная оценка

После генерации отзывов была проведена визуальная оценка их качества. 

![img](https://github.com/sultanovemil/PP_3_URFU/blob/main/img/examples.PNG)

В целом, данные отзывы можно оценить как среднего качества. Среди них встречаются как хорошо структурированные и информативные тексты, так и те, которые нуждаются в улучшении.


Для количественной оценки качества модели данные были сгруппированы по категориям, и для каждой категории объединялись тексты отзывов. 

![img](https://github.com/sultanovemil/PP_3_URFU/blob/main/img/grouped.PNG)


Мы вычислили среднее значение perplexity для каждой категории, что позволило оценить языковую связность и грамотность текста. Кроме того, используя набор ключевых слов для каждой категории, мы рассчитали процент присутствия этих ключевых слов в объединённом тексте относительно общего их количества. Это дало возможность измерить тематическую релевантность сгенерированных отзывов.


#### Комплексная оценка качества модели

Комбинируя показатели perplexity и покрытие ключевых слов, мы получили комплексную оценку качества модели. Этот подход учитывает как языковую точность, так и соответствие содержанию заданным категориям. Высокий процент ключевых слов указывает на значительную релевантность контента, в то время как значения perplexity помогают оценить качество и связность текста.

![img](https://github.com/sultanovemil/PP_3_URFU/blob/main/img/visualization.png)

Можно сделать следующие выводы о качестве генерирования отзывов:

Высокий процент ключевых слов указывает на значительную релевантность контента. Например, категория "Магазин продуктов" демонстрирует 87.5% ключевых слов, что свидетельствует о фокусе на основных аспектах темы.

Значения перплексии, варьирующиеся от 27.37 до 33.97, указывают на различную сложность текста. Низкая перплексия в категории "Гостиница" может отражать более простую и прямую структуру отзывов, что улучшает читаемость.

Разнообразие ключевых слов по различным категориям (например, "цена", "персонал") предполагает способность модели охватить основные аспекты каждой темы, способствуя созданию содержательного отзыва.

Это указывает на способность нейронной сети генерировать содержательные и тематически релевантные отзывы, отражающие основные аспекты каждой категории.

---
### Заключение

Проект позволил создать модель, способную генерировать текстовые отзывы на основе заданных параметров. 

---

Веб-приложение развернуто на Hugging Face Spaces и доступно по следующей [ссылке](https://huggingface.co/spaces/Emil25/PP3_Team_1)


![app](https://github.com/sultanovemil/PP_3_URFU/blob/main/img/app.png)

